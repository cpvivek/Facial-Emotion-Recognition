{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_DL&MLE_Facial_Emotion_Recognition_Vivek_CP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpvivek/Facial-Emotion-Recognition/blob/main/Capstone_DL%26MLE_Facial_Emotion_Recognition_Vivek_CP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_adQ5zbi5U3Z"
      },
      "source": [
        "# Facial Emotion Detection\n",
        "In this project, we are aiming to develop a CNN netwrok to detect 7 different human emotions in real time over a live web-cam feed. We'll also be deploying a web app to run this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTagtqGLoXLd"
      },
      "source": [
        "Importing necessary libraries including tensorflow, keras, sklearn and opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I200zV42T-ye"
      },
      "source": [
        "# import necessary files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH3rfnChvO5m"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72-k5mJMofof"
      },
      "source": [
        "Importing dataset sourced from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dGzzjaX_ynd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5fec74a-142d-49b7-e3ff-674d79183cc1"
      },
      "source": [
        "# mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VawKE3CGomDk"
      },
      "source": [
        "reading the csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FDaaif4sb2p"
      },
      "source": [
        "file_path='/content/drive/MyDrive/Alma Better Pro/Alma Better Pro Program/Module 4: Machine Learning/Data Sets/icml_face_data.csv'\n",
        "\n",
        "df=pd.read_csv(file_path) #facial emotion data stored as a dataframe in fe_df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look into our dataset"
      ],
      "metadata": {
        "id": "VQUjjIU6wDbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuJoqvJ3wIV0",
        "outputId": "ff379200-6638-44f5-b377-46d3ab70b9e5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['emotion', ' Usage', ' pixels'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the dataset is not all that complicated.\n",
        "\n",
        "We've got 'emotion' field indicating different emotions.\n",
        "\n",
        "I believe since this is a dataset used in kaggle competitions, they've went ahead and done the training, validation and test segregation, labeled by 'Usage' column\n",
        "\n",
        "And finally in the 'pixels' field, we have the pixelated form of the image, flattened into an 1 dimension array. "
      ],
      "metadata": {
        "id": "l0v6Ru-BwKYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu_6lrbYv93R",
        "outputId": "eccdbecf-f07d-4150-879c-afd306325c5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35887 entries, 0 to 35886\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  35887 non-null  int64 \n",
            " 1    Usage   35887 non-null  object\n",
            " 2    pixels  35887 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 841.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pixel field is stored as a string at the moment. We'll have to convert that into a 48x48x1 array with float values."
      ],
      "metadata": {
        "id": "SQQXxPdgwwTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using lambda function to achieve this conversion\n",
        "df[' pixels']=df[' pixels'].apply(lambda x: np.fromstring(x, sep=' ',dtype='float32')) #converting string to float separated by ' ' \n",
        "df[' pixels']=df[' pixels'].apply(lambda x:np.asarray(x.reshape(48,48,1))) #reshaping to 48x48x1"
      ],
      "metadata": {
        "id": "iR7QUDPLiqgH"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look into emotions field."
      ],
      "metadata": {
        "id": "27sj2NJR_EE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotion'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFYx4zsX_Bsu",
        "outputId": "14da61df-a889-4bd6-c3bf-27fa24d53e97"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 4, 6, 3, 5, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 7 different emotions labeled using number from 0 to 6."
      ],
      "metadata": {
        "id": "U7QM5p3bb_ZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's segregate our training, validation and test sets right away. \n",
        "\n",
        "Public Test would be put into validation and Private test into test set. "
      ],
      "metadata": {
        "id": "jobLtXfu_2Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#defininng train, val and test data.\n",
        "training_data=df[df[' Usage']=='Training']\n",
        "validation_data=df[df[' Usage']=='PublicTest']\n",
        "testing_data=df[df[' Usage']=='PrivateTest']"
      ],
      "metadata": {
        "id": "cv6UTPyhAtTP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data['emotion'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnVhkAlVBV8m",
        "outputId": "b36f444b-e1a3-426c-f37c-b3ff142dfe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    7215\n",
              "6    4965\n",
              "4    4830\n",
              "2    4097\n",
              "0    3995\n",
              "5    3171\n",
              "1     436\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there is considerable amount of imbalance in the dataset wrt to emotions. This will create bias in the model and result in misclassifying. \n",
        "\n",
        "We can treat this issue by data augmentation."
      ],
      "metadata": {
        "id": "1EqSHNiPccDC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3SouBFAovQm"
      },
      "source": [
        "Using keras for data augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5Hd0XZW2_WA"
      },
      "source": [
        "# Data Augmentation\n",
        "from keras import layers\n",
        "data_augmentation=keras.Sequential(\n",
        "    [\n",
        "     layers.RandomFlip('horizontal'), #introduce some random flips on horizontal axis\n",
        "     layers.RandomRotation(0.015), #introduce some rotation by 0.015 degree\n",
        "     layers.RandomZoom(0.15,0.15) #introduce some random zoom\n",
        "    ]\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6chXbR7BpOD-"
      },
      "source": [
        "Applying Data Augmentation on training samples so that each emotion sample has equal number of samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Mlr7tSks09Y"
      },
      "source": [
        "aug_df=pd.DataFrame({}) #creating a neww dataframe that will contain the augmented images\n",
        "emotion=[] #list for emotion labels\n",
        "aug_pixels=[] #list for augemnted image pixels\n",
        "sample_length=7500 #specifying desired number of samples for each emotions. arbitrary choice\n",
        "\n",
        "for i in range(7): #since 7 emotions\n",
        "  data=training_data[training_data['emotion']==i] #selecting the image to be augmented\n",
        "  j=sample_length - len(data) #calculating number of samples required to reach 7500\n",
        "  for k in range(j):\n",
        "    ind= k%len(data) #setting index\n",
        "    augmented_image=data_augmentation(data[' pixels'][data.index[ind]]) #augmenting images\n",
        "    aug_pixels.append(augmented_image) #appending augmented image to \n",
        "    emotion.append(i)#appending emotion label\n",
        "\n",
        "aug_df[' pixels'] = aug_pixels #column containing augmented pixels\n",
        "aug_df['emotion']= emotion#corresponding emotion label"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8XmdhG4crYN",
        "outputId": "4a77fdb2-d4b0-49be-b116-6446810f108a"
      },
      "source": [
        "#count of augmented images that will be added for each emotions\n",
        "aug_df['emotion'].value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    7064\n",
              "5    4329\n",
              "0    3505\n",
              "2    3403\n",
              "4    2670\n",
              "6    2535\n",
              "3     285\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RHQF13CIbG4e",
        "outputId": "3f464d50-e7ec-4f27-d2ce-5bb84da701ae"
      },
      "source": [
        "# concat train data and augmented df\n",
        "training_data=pd.concat([training_data,aug_df],axis=0)\n",
        "training_data['emotion'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7500\n",
              "2    7500\n",
              "4    7500\n",
              "6    7500\n",
              "3    7500\n",
              "5    7500\n",
              "1    7500\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-Up08GIphoB"
      },
      "source": [
        "Since augmented data and training data index wouldn't matchup, we need set up proper index for the new training dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5QhByxIThklb",
        "outputId": "1cf64556-fc3b-4af5-baab-40ef958243d1"
      },
      "source": [
        "ind=[ind for ind in range(len(training_data))]\n",
        "training_data.index=ind\n",
        "training_data.tail()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       emotion  Usage                                             pixels\n",
              "52495        6    NaN  (((tf.Tensor(60.324055, shape=(), dtype=float3...\n",
              "52496        6    NaN  (((tf.Tensor(97.73027, shape=(), dtype=float32...\n",
              "52497        6    NaN  (((tf.Tensor(135.17743, shape=(), dtype=float3...\n",
              "52498        6    NaN  (((tf.Tensor(164.44943, shape=(), dtype=float3...\n",
              "52499        6    NaN  (((tf.Tensor(23.85661, shape=(), dtype=float32..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-63c194bd-e93c-4362-86be-447c076a7618\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>Usage</th>\n",
              "      <th>pixels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>52495</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(((tf.Tensor(60.324055, shape=(), dtype=float3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52496</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(((tf.Tensor(97.73027, shape=(), dtype=float32...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52497</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(((tf.Tensor(135.17743, shape=(), dtype=float3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52498</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(((tf.Tensor(164.44943, shape=(), dtype=float3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52499</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>(((tf.Tensor(23.85661, shape=(), dtype=float32...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63c194bd-e93c-4362-86be-447c076a7618')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-63c194bd-e93c-4362-86be-447c076a7618 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-63c194bd-e93c-4362-86be-447c076a7618');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So we have 52499 datapoints now. Ignore the NaN values in usage. We know the usage is training"
      ],
      "metadata": {
        "id": "trdHWG5p2FnM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN8crTUqpoOJ"
      },
      "source": [
        "Preprocessing X_train using keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlKUs7Dgo-iS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30b4782-b57d-4d58-b966-48a7f9cb44fc"
      },
      "source": [
        "x_train=[]\n",
        "for i in training_data[' pixels']:\n",
        "  x_train.append(i)\n",
        "x_train=np.asarray(x_train)\n",
        "x_train=x_train.reshape(len(x_train),48,48,1)\n",
        "y_train=np.array(training_data['emotion'])\n",
        "y_train=y_train.astype(int)\n",
        "y_train=np_utils.to_categorical(y_train,7)\n",
        "# shape of training data\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((52500, 48, 48, 1), (52500, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBw-ql-BpuFm"
      },
      "source": [
        "Preprocessing X_val using keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQ-pAHq9zuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab19f6cd-2f54-4f22-9dc3-98c59315369a"
      },
      "source": [
        "x_val = []\n",
        "for i in validation_data[' pixels']:\n",
        "  x_val.append(i)\n",
        "x_val=np.asarray(x_val)\n",
        "x_val= x_val.reshape(len(x_val),48,48,1)\n",
        "y_val=np.array(validation_data['emotion'])\n",
        "y_val=y_val.astype(int)\n",
        "y_val=np_utils.to_categorical(y_val,7)\n",
        "\n",
        "\n",
        "\n",
        "x_val.shape,y_val.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3589, 48, 48, 1), (3589, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ggjy26zpwU7"
      },
      "source": [
        "Preprocessing x_test using keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC60Rvk8v4Td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184aeae6-a455-4e6c-cce2-ffeccf221d55"
      },
      "source": [
        "x_test = []\n",
        "\n",
        "for i in testing_data[' pixels']:\n",
        "  x_test.append(i)\n",
        "x_test=np.array(x_test)\n",
        "x_test=x_test.reshape(len(x_test),48,48,1)\n",
        "y_test=np.array(test_data['emotion'])\n",
        "y_test=y_test.astype(int)\n",
        "y_test=np_utils.to_categorical(y_test,7)\n",
        "# code here\n",
        "\n",
        "# then check shape\n",
        "x_test.shape,y_test.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3589, 48, 48, 1), (3589, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    }
  ]
}