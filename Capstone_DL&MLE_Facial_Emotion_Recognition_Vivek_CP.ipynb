{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capstone_DL&MLE_Facial_Emotion_Recognition_Vivek_CP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cpvivek/Facial-Emotion-Recognition/blob/main/Capstone_DL%26MLE_Facial_Emotion_Recognition_Vivek_CP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_adQ5zbi5U3Z"
      },
      "source": [
        "# Facial Emotion Detection\n",
        "In this project, we are aiming to develop a CNN netwrok to detect 7 different human emotions in real time over a live web-cam feed. We'll also be deploying a web app to run this model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTagtqGLoXLd"
      },
      "source": [
        "Importing necessary libraries including tensorflow, keras, sklearn and opencv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I200zV42T-ye"
      },
      "source": [
        "# import necessary files\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH3rfnChvO5m"
      },
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72-k5mJMofof"
      },
      "source": [
        "Importing dataset sourced from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dGzzjaX_ynd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "a2dbda3e-24b6-436d-cd80-60c7aff8ba79"
      },
      "source": [
        "# mounting drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1ecb5de04d6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# mounting drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_ms\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       ephemeral=True)\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     _message.blocking_request(\n\u001b[0;32m--> 124\u001b[0;31m         'request_auth', request={'authType': 'dfs_ephemeral'}, timeout_sec=None)\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m   \u001b[0mmountpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_os\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    173\u001b[0m   request_id = send_request(\n\u001b[1;32m    174\u001b[0m       request_type, request, parent=parent, expect_reply=True)\n\u001b[0;32m--> 175\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    104\u001b[0m         reply.get('colab_msg_id') == message_id):\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VawKE3CGomDk"
      },
      "source": [
        "reading the csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FDaaif4sb2p"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Alma Better Pro/Alma Better Pro Program/Module 4: Machine Learning/Data Sets/icml_face_data.csv')\n",
        "# for i in range(len(df[' pixels'])):\n",
        "#   df[' pixels'][i] = np.fromstring(df[' pixels'][i],sep=' ',dtype='float32')\n",
        "#   df[' pixels'][i] = np.asarray(df[' pixels'][i]).reshape(48,48,1)\n",
        "# train_data = df[df[' Usage']=='Training']\n",
        "# val_data = df[df[' Usage']=='PublicTest']\n",
        "# test_data = df[df[' Usage']=='PrivateTest']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look into our dataset"
      ],
      "metadata": {
        "id": "VQUjjIU6wDbp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QuJoqvJ3wIV0",
        "outputId": "ff379200-6638-44f5-b377-46d3ab70b9e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['emotion', ' Usage', ' pixels'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So the dataset is not all that complicated.\n",
        "\n",
        "We've got 'emotion' field indicating different emotions.\n",
        "\n",
        "I believe since this is a dataset used in kaggle competitions, they've went ahead and done the training, validation and test segregation, labeled by 'Usage' column\n",
        "\n",
        "And finally in the 'pixels' field, we have the pixelated form of the image, flattened into an 1 dimension array. "
      ],
      "metadata": {
        "id": "l0v6Ru-BwKYy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yu_6lrbYv93R",
        "outputId": "5d572653-6455-4fd8-c6e8-b5b1820892b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 35887 entries, 0 to 35886\n",
            "Data columns (total 3 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   emotion  35887 non-null  int64 \n",
            " 1    Usage   35887 non-null  object\n",
            " 2    pixels  35887 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 841.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pixel field is stored as a string at the moment. We'll have to convert that into a 48x48x1 array with float values."
      ],
      "metadata": {
        "id": "SQQXxPdgwwTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using lambda function to achieve this conversion\n",
        "df[' pixels']=df[' pixels'].apply(lambda x: np.fromstring(x, sep=' ',dtype='float32')) #converting string to float separated by ' ' \n",
        "df[' pixels']=df[' pixels'].apply(lambda x:np.asarray(x.reshape(48,48,1))) #reshaping to 48x48x1"
      ],
      "metadata": {
        "id": "iR7QUDPLiqgH"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look into emotions field."
      ],
      "metadata": {
        "id": "27sj2NJR_EE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['emotion'].unique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFYx4zsX_Bsu",
        "outputId": "e2b962c7-07dd-4c46-86e3-6575d972ea88"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 4, 6, 3, 5, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains 7 different emotions labeled using number from 0 to 6."
      ],
      "metadata": {
        "id": "U7QM5p3bb_ZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's segregate our training, validation and test sets right away. \n",
        "\n",
        "Public Test would be put into validation and Private test into test set. "
      ],
      "metadata": {
        "id": "jobLtXfu_2Yl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[' Usage'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX41-YAO5XZ5",
        "outputId": "0fb91573-e337-477b-ad5b-afc565ce6aec"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Training       28709\n",
              "PublicTest      3589\n",
              "PrivateTest     3589\n",
              "Name:  Usage, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defininng train, val and test data.\n",
        "training_data=df[df[' Usage']=='Training']\n",
        "validation_data=df[df[' Usage']=='PublicTest']\n",
        "testing_data=df[df[' Usage']=='PrivateTest']"
      ],
      "metadata": {
        "id": "cv6UTPyhAtTP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data['emotion'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnVhkAlVBV8m",
        "outputId": "843d54e0-4c59-4677-b783-fa1a777c4cb0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    7215\n",
              "6    4965\n",
              "4    4830\n",
              "2    4097\n",
              "0    3995\n",
              "5    3171\n",
              "1     436\n",
              "Name: emotion, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that there is considerable amount of imbalance in the dataset wrt to emotions in training dataset. This will create bias in the model and result in misclassifying. \n",
        "\n",
        "We can treat this issue by data augmentation."
      ],
      "metadata": {
        "id": "1EqSHNiPccDC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s3SouBFAovQm"
      },
      "source": [
        "Using keras for data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN8crTUqpoOJ"
      },
      "source": [
        "x_train formation\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tlKUs7Dgo-iS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7f4451d-51e4-43af-cb4c-343403383576"
      },
      "source": [
        "x_train=[]\n",
        "for i in range(len(training_data[' pixels'])):\n",
        "  x_train.append(training_data[' pixels'][i])\n",
        "x_train=np.asarray(x_train) #since we need arrays as input to CNN \n",
        "x_train=x_train.reshape(len(x_train),48,48,1)\n",
        "y_train=np.array(training_data['emotion'])\n",
        "y_train=y_train.astype(int)\n",
        "y_train=np_utils.to_categorical(y_train,7)\n",
        "# shape of training data\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((28709, 48, 48, 1), (28709, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBw-ql-BpuFm"
      },
      "source": [
        "x_val"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObQ-pAHq9zuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9432ae76-1263-4ffb-c521-27b8599ab97c"
      },
      "source": [
        "x_val = []\n",
        "for i in validation_data[' pixels']:\n",
        "  x_val.append(i)\n",
        "x_val=np.asarray(x_val)\n",
        "x_val= x_val.reshape(len(x_val),48,48,1)\n",
        "y_val=np.array(validation_data['emotion'])\n",
        "y_val=y_val.astype(int)\n",
        "y_val=np_utils.to_categorical(y_val,7)\n",
        "\n",
        "\n",
        "\n",
        "x_val.shape,y_val.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3589, 48, 48, 1), (3589, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ggjy26zpwU7"
      },
      "source": [
        "Preprocessing x_test using keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sC60Rvk8v4Td",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f76b5e3-7293-4119-9dc9-f5c2563c1b07"
      },
      "source": [
        "x_test = []\n",
        "\n",
        "for i in testing_data[' pixels']:\n",
        "  x_test.append(i)\n",
        "x_test=np.array(x_test)\n",
        "x_test=x_test.reshape(len(x_test),48,48,1)\n",
        "y_test=np.array(testing_data['emotion'])\n",
        "y_test=y_test.astype(int)\n",
        "y_test=np_utils.to_categorical(y_test,7)\n",
        "# code here\n",
        "\n",
        "# then check shape\n",
        "x_test.shape,y_test.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3589, 48, 48, 1), (3589, 7))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation Process.\n",
        "\n",
        "We can observe that there is a imbalance in labels in train, val and test sets. This will result in bias in the model twoards certain emotions.\n",
        "\n",
        "We'll be able to sort this issue adding augmented images to data to deal with imbalance."
      ],
      "metadata": {
        "id": "-QvTQIujFdup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen= ImageDataGenerator(\n",
        "    rescale=1./255, #rescaling\n",
        "    rotation_range=10,#rotating the image\n",
        "    horizontal_flip=True,#flipping the image horizontally\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1, #shift in width and height\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "testgen= ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "2k5QooYQFgQ8"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datagen.fit(x_train)"
      ],
      "metadata": {
        "id": "nnZc3EWyHM6u"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_flow=datagen.flow(x_train,y_train,batch_size=64)\n",
        "test_flow=testgen.flow(x_test,y_test,batch_size=64)"
      ],
      "metadata": {
        "id": "ide0DSrfH92S"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building models usign keras layers and keras sequential model"
      ],
      "metadata": {
        "id": "2-EWkalSsTkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n"
      ],
      "metadata": {
        "id": "YPOYqwX9JStx"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FER_Model(input_shape=(48,48,1)):\n",
        "  visible=Input(shape=input_shape,name='input')\n",
        "  num_classes=7\n",
        "\n",
        "  #1st block\n",
        "  conv1_1=Conv2D(64,kernel_size=3, activation='relu', padding='same', name='conv1_1')(visible)\n",
        "  conv1_1=BatchNormalization()(conv1_1)\n",
        "  conv1_2=Conv2D(64,kernel_size=3,activation='relu', padding='same', name='conv1_2')(conv1_1)\n",
        "  conv1_2=BatchNormalization()(conv1_2)\n",
        "  pool1_1=MaxPooling2D(pool_size=(2,2), name='pool1_1')(conv1_2)\n",
        "  drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
        "\n",
        "#2nd Block \n",
        "  conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
        "  conv2_1 = BatchNormalization()(conv2_1)\n",
        "  conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "  conv2_2 = BatchNormalization()(conv2_2)\n",
        "  conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "  conv2_2 = BatchNormalization()(conv2_3)\n",
        "  pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "  drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
        "  \n",
        "  #3rd block\n",
        "\n",
        "  conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "  conv3_1 = BatchNormalization()(conv3_1)\n",
        "  conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "  conv3_2 = BatchNormalization()(conv3_2)\n",
        "  conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
        "  conv3_3 = BatchNormalization()(conv3_3)\n",
        "  conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "  conv3_4 = BatchNormalization()(conv3_4)\n",
        "  pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "  drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
        " \n",
        " #4th block\n",
        " \n",
        "  conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "  conv4_1 = BatchNormalization()(conv4_1)\n",
        "  conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "  conv4_2 = BatchNormalization()(conv4_2)\n",
        "  conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "  conv4_3 = BatchNormalization()(conv4_3)\n",
        "  conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "  conv4_4 = BatchNormalization()(conv4_4)\n",
        "  pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "  drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
        "    \n",
        "  #the 5-th block\n",
        "  \n",
        "  conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "  conv5_1 = BatchNormalization()(conv5_1)\n",
        "  conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "  conv5_2 = BatchNormalization()(conv5_2)\n",
        "  conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "  conv5_3 = BatchNormalization()(conv5_3)\n",
        "  conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "  conv5_3 = BatchNormalization()(conv5_3)\n",
        "  pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "  drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
        "  flatten = Flatten(name = 'flatten')(drop5_1)\n",
        "  ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model \n",
        "  model = Model(inputs =visible, outputs = ouput)\n",
        "   # summary layers\n",
        "  print(model.summary())\n",
        "    \n",
        "  return model"
      ],
      "metadata": {
        "id": "BfZ-hkfuIeKB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=FER_Model()\n",
        "opt=tf.keras.optimizers.Adam(lr=0.0001,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfT4HNJbK_w0",
        "outputId": "1524da7d-9ef5-4cb9-bfd7-9f8cc863357e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 48, 48, 64)       256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_6 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_7 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_8 (Batc  (None, 12, 12, 256)      1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_9 (Batc  (None, 6, 6, 256)        1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_10 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_11 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 6, 6, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 3, 3, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv5_4 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,111,367\n",
            "Trainable params: 13,103,431\n",
            "Non-trainable params: 7,936\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100  \n",
        "history = model.fit_generator(train_flow, \n",
        "                    steps_per_epoch=len(x_train) / 64, \n",
        "                    epochs=num_epochs,  \n",
        "                    verbose=1,  \n",
        "                    validation_data=test_flow)\n"
      ],
      "metadata": {
        "id": "F_vJ-niKNh3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLAf5-yhYt8N",
        "outputId": "78f29e6a-6b44-4efc-c58c-f5113ef15975"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved model to disk\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer Learning"
      ],
      "metadata": {
        "id": "DoDss5yhs3gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=tf.keras.applications.MobileNetV2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6bflZapswsW",
        "outputId": "0155576b-43d7-4b7a-b2ee-c868232dafc5"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14540800/14536120 [==============================] - 0s 0us/step\n",
            "14548992/14536120 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=224\n",
        "new_array=cv2.resize(_ )"
      ],
      "metadata": {
        "id": "4qun9QZ-uOpC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}